{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackedEnsembleTest",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qje27QyUvmEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from random import randint\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from scipy.spatial import distance\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuElUqJaLZHQ",
        "colab_type": "code",
        "outputId": "797a5d06-3cf9-4dae-b5d5-63778c2a8a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "omU9AKq8OwID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/My Drive/Dataset/fashion-mnist_train.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/Dataset/fashion-mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b65AT9E3Uyvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_classifier(classifier_type, tree_min_samples_split = 20):\n",
        "\n",
        "    if classifier_type == \"svm\":\n",
        "        c = svm.SVC(probability=True)\n",
        "\n",
        "    elif classifier_type == \"logreg\":\n",
        "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "\n",
        "    elif classifier_type == \"knn\":\n",
        "        c = neighbors.KNeighborsClassifier()\n",
        "\n",
        "    elif classifier_type == \"tree\":\n",
        "        c = tree.DecisionTreeClassifier(min_samples_split = tree_min_samples_split)\n",
        "\n",
        "    elif classifier_type == \"randomforest\":\n",
        "        c = ensemble.RandomForestClassifier()\n",
        "        \n",
        "    else:\n",
        "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "    \n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4YXXAFycOw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create a sample of train_data for fast training\n",
        "data_sampling_rate = 0.1\n",
        "train_data = train_data.sample(frac=data_sampling_rate)\n",
        "target = \"label\"\n",
        "X = [i for i in train_data.columns if i not in target]\n",
        "X = train_data[X]\n",
        "y = train_data[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "il2N4v5EcUFT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
        "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
        "    \n",
        "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    base_estimators: list \n",
        "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
        "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
        "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
        "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
        "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
        "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
        "    classifier_duplicates: int, optional (default = 1)\n",
        "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
        "    stack_layer_classifier: string, optional (default = \"logreg')\n",
        "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
        "    training_folds: int, optional (default = 4)\n",
        "        How many folds will be used to generate the training set for the stacked layer\n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    classes_ : array of shape = [n_classes] \n",
        "        The classes labels (single output problem).\n",
        "\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The default values for most base learners are used.\n",
        "\n",
        "    See also\n",
        "    --------\n",
        "    \n",
        "    ----------\n",
        "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
        "            Super Learner. Statistical Applications in Genetics \n",
        "            and Molecular Biology, 6(1) \n",
        "            doi:10.2202/1544-6115.1309\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import load_iris\n",
        "    >>> from sklearn.model_selection import cross_val_score\n",
        "    >>> clf = StackedEnsembleClassifier()\n",
        "    >>> iris = load_iris()\n",
        "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
        "\n",
        "    \"\"\"\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
        "        \"\"\"Setup a SuperLearner classifier .\n",
        "        Parameters\n",
        "        ----------\n",
        "        base_estimator_types: The types of classifiers to include at the base layer\n",
        "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
        "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Nothing\n",
        "        \"\"\"     \n",
        "\n",
        "        # Initialise class variabels\n",
        "        self.base_estimator_types = base_estimator_types\n",
        "        self.base_estimator_type_list = list()\n",
        "        self.base_estimator_duplicates = base_estimator_duplicates\n",
        "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "\n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            The training input samples. \n",
        "        y : array-like, shape = [n_samples] \n",
        "            The target values (class labels) as integers or strings.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"    \n",
        "        \n",
        "        # Check that X and y have correct shape\n",
        "        X, y = check_X_y(X, y)\n",
        "        # Store the classes seen during fit\n",
        "        self.classes_ = unique_labels(y)\n",
        "        \n",
        "        ########################\n",
        "        # LEVEL 0\n",
        "        ########################\n",
        "        \n",
        "        # Set up the base classifeirs in the ensemble\n",
        "        self.classifiers_ = list()\n",
        "        \n",
        "        for i in range(0, self.base_estimator_duplicates):\n",
        "            for t in self.base_estimator_types:\n",
        "\n",
        "                self.base_estimator_type_list.append(t)      \n",
        "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "                self.classifiers_.append(c)\n",
        "        \n",
        "        # Store the number of classifers in the ensemble\n",
        "        self.n_estimators_ = len(self.classifiers_)\n",
        "\n",
        "        # Use all training data to train base classifiers\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "        \n",
        "        # Set up empty arrays to hold stack layer training data\n",
        "        self.X_stack_train = None #(dtype = float)\n",
        "        self.y_stack_train = y_train\n",
        "          \n",
        "        # Train each base calssifier and generate the stack layer training dataset\n",
        "        for classifier in self.classifiers_:\n",
        "\n",
        "            # Extract a bootstrap sample\n",
        "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
        "            \n",
        "            # Train a base classifier\n",
        "            classifier.fit(X_train_samp, y_train_samp)\n",
        "            \n",
        "            # Make predictions for all instances in the training set\n",
        "            y_pred = classifier.predict_proba(X_train)\n",
        "\n",
        "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
        "            try:\n",
        "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
        "            except ValueError:\n",
        "                self.X_stack_train = y_pred\n",
        "      \n",
        "        ########################\n",
        "        # LEVEL 1\n",
        "        ########################\n",
        "        \n",
        "        # Create the stack layer classifier\n",
        "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "        # Train the stack layer using the newly created dataset\n",
        "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "            \n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels of the input samples X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "        Returns\n",
        "        -------\n",
        "        p : array of shape = [n_samples, ].\n",
        "            The predicted class labels of the input samples. \n",
        "        \"\"\"\n",
        "        \n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "        # Check that the input features match the type and shape of the training features\n",
        "        X = check_array(X)\n",
        "   \n",
        "        X_stack_queries = None\n",
        "              \n",
        "        # Make a prediction with each base classifier and assemble the stack layer query\n",
        "        for classifier in self.classifiers_:\n",
        "            \n",
        "            y_pred = classifier.predict_proba(X)\n",
        "            \n",
        "            try:\n",
        "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "            except ValueError:\n",
        "                X_stack_queries = y_pred\n",
        "        \n",
        "        # Return the prediction made by the stack layer classifier\n",
        "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "    \n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict class probabilities of the input samples X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "        Returns\n",
        "        -------\n",
        "        p : array of shape = [n_samples, n_labels].\n",
        "            The predicted class label probabilities of the input samples. \n",
        "        \"\"\"\n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "        # Check that the input features match the type and shape of the training features\n",
        "        X = check_array(X)\n",
        "        \n",
        "        X_stack_queries = None\n",
        "        \n",
        "        # Make a prediction with each base classifier\n",
        "        for classifier in self.classifiers_:\n",
        "            \n",
        "            y_pred = classifier.predict_proba(X)\n",
        "                \n",
        "            try:\n",
        "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "            except ValueError:\n",
        "                X_stack_queries = y_pred\n",
        "\n",
        "        # Return the prediction made by the stack layer classifier        \n",
        "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VC7SSxIfVAGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class StackedEnsembleHoldOut(BaseEstimator, ClassifierMixin):\n",
        "  # Constructor for the classifier object\n",
        "  def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 2, stack_layer_classifier_type = \"logreg\"):\n",
        "    # Initialise class variabels\n",
        "    self.base_estimator_types = base_estimator_types\n",
        "    self.base_estimator_type_list = list()\n",
        "    self.base_estimator_duplicates = base_estimator_duplicates\n",
        "    self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "\n",
        "  # The fit function to train a classifier\n",
        "  def fit(self, X, y):\n",
        "    # Check that X and y have correct shape\n",
        "    X, y = check_X_y(X, y)\n",
        "        \n",
        "    # Store the classes seen during fit\n",
        "    self.classes_ = unique_labels(y)\n",
        "        \n",
        "    # Set up the base classifeirs in the ensemble\n",
        "    self.classifiers_ = list()\n",
        "    \n",
        "    for i in range(0, self.base_estimator_duplicates):\n",
        "      \n",
        "      for t in self.base_estimator_types:\n",
        "        \n",
        "        self.base_estimator_type_list.append(t)      \n",
        "        c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "        self.classifiers_.append(c)\n",
        "        \n",
        "    # Store the number of classifers in the ensemble\n",
        "    self.n_estimators_ = len(self.classifiers_)\n",
        "        \n",
        "    # Set up empty arrays to hold stack layer training data\n",
        "    self.X_stack_train = None #(dtype = float)\n",
        "    self.y_stack_train = None\n",
        "    \n",
        "    #create a hold out set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\\\n",
        "                                                              train_size = 0.8)\n",
        "        \n",
        "    # Append the true value of hold out set to y_stack_train\n",
        "    try:\n",
        "      self.y_stack_train = np.c_[self.y_stack_train, y_test]\n",
        "    except ValueError:\n",
        "      self.y_stack_train = y_test #* might need to change\n",
        "    \n",
        "    for classifier in self.classifiers_:\n",
        "      # Train a base classifier\n",
        "      classifier.fit(X_train, y_train)\n",
        "      \n",
        "      # Make predictions for all instances in the hold out set\n",
        "      y_pred = classifier.predict_proba(X_test)\n",
        "\n",
        "      # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
        "      try:\n",
        "        self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
        "      except ValueError:\n",
        "        self.X_stack_train = y_pred #* might need to change\n",
        "    \n",
        "    # Create the stack layer classifier\n",
        "    self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "    # Train the stack layer using the newly created dataset\n",
        "    self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "                \n",
        "    return self\n",
        "    \n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict(self, X):\n",
        "    \"\"\"Predict class labels of the input samples X.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like matrix of shape = [n_samples, n_features]\n",
        "    \n",
        "    The input samples. \n",
        "    Returns\n",
        "    -------\n",
        "    p : array of shape = [n_samples, ].\n",
        "            The predicted class labels of the input samples. \n",
        "        \"\"\"\n",
        "        \n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "   \n",
        "    X_stack_queries = None\n",
        "              \n",
        "    # Make a prediction with each base classifier and assemble the stack layer query\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      \n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "        \n",
        "    # Return the prediction made by the stack layer classifier\n",
        "    return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "      \n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict_proba(self, X):\n",
        "    \"\"\"Predict class probabilities of the input samples X.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "    Returns\n",
        "    -------\n",
        "    p : array of shape = [n_samples, n_labels].\n",
        "         The predicted class label probabilities of the input samples. \n",
        "        \"\"\"\n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "        \n",
        "    X_stack_queries = None\n",
        "        \n",
        "    # Make a prediction with each base classifier\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      \n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "\n",
        "    # Return the prediction made by the stack layer classifier        \n",
        "    return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlRQKwRw28Ur",
        "colab_type": "code",
        "outputId": "def772cd-a190-44a1-9b47-354b9ecf8121",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "clf = StackedEnsembleHoldOut()\n",
        "clf.fit(X, y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedEnsembleHoldOut(base_estimator_duplicates=2,\n",
              "            base_estimator_types=['svm', 'logreg', 'tree'],\n",
              "            stack_layer_classifier_type='logreg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "ETHBhvMhtOWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1969
        },
        "outputId": "75e339c2-e69d-460a-97a4-3d86004bdde0"
      },
      "cell_type": "code",
      "source": [
        "x_hold = pd.DataFrame(clf.X_stack_train)\n",
        "x_hold"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1170</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1171</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1172</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1173</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1174</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1175</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1176</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1177</th>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1178</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1179</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1180</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1185</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1189</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1190</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1191</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1192</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1193</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1194</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1200 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0  1  2  3  4  5\n",
              "0     3  4  4  3  4  4\n",
              "1     3  3  3  3  3  3\n",
              "2     3  2  4  3  2  4\n",
              "3     3  8  5  3  8  5\n",
              "4     3  0  0  3  0  0\n",
              "5     3  4  2  3  4  2\n",
              "6     3  1  1  3  1  1\n",
              "7     3  8  8  3  8  8\n",
              "8     3  9  9  3  9  9\n",
              "9     3  4  4  3  4  4\n",
              "10    3  4  4  3  4  4\n",
              "11    3  9  9  3  9  9\n",
              "12    3  4  4  3  4  4\n",
              "13    3  2  8  3  2  8\n",
              "14    3  9  9  3  9  9\n",
              "15    3  7  7  3  7  7\n",
              "16    3  6  4  3  6  4\n",
              "17    3  3  3  3  3  3\n",
              "18    3  7  7  3  7  7\n",
              "19    3  1  1  3  1  1\n",
              "20    3  2  6  3  2  6\n",
              "21    3  1  1  3  1  1\n",
              "22    3  1  1  3  1  1\n",
              "23    3  8  8  3  8  8\n",
              "24    3  8  8  3  8  8\n",
              "25    3  1  1  3  1  1\n",
              "26    3  1  1  3  1  1\n",
              "27    3  7  7  3  7  7\n",
              "28    3  4  3  3  4  3\n",
              "29    3  0  0  3  0  0\n",
              "...  .. .. .. .. .. ..\n",
              "1170  3  1  1  3  1  1\n",
              "1171  3  8  8  3  8  8\n",
              "1172  3  1  3  3  1  3\n",
              "1173  3  2  3  3  2  3\n",
              "1174  3  5  5  3  5  5\n",
              "1175  3  7  7  3  7  7\n",
              "1176  3  0  0  3  0  0\n",
              "1177  3  9  9  3  9  9\n",
              "1178  3  6  0  3  6  0\n",
              "1179  3  6  6  3  6  6\n",
              "1180  3  0  0  3  0  0\n",
              "1181  3  4  3  3  4  3\n",
              "1182  3  1  1  3  1  1\n",
              "1183  3  4  8  3  4  8\n",
              "1184  3  3  3  3  3  3\n",
              "1185  3  1  1  3  1  1\n",
              "1186  3  8  8  3  8  8\n",
              "1187  3  8  8  3  8  8\n",
              "1188  3  8  8  3  8  8\n",
              "1189  3  4  4  3  4  4\n",
              "1190  3  6  6  3  6  6\n",
              "1191  3  0  6  3  0  6\n",
              "1192  3  7  7  3  7  7\n",
              "1193  3  3  6  3  3  6\n",
              "1194  3  3  3  3  3  3\n",
              "1195  3  7  7  3  7  7\n",
              "1196  3  4  4  3  4  4\n",
              "1197  3  2  0  3  2  0\n",
              "1198  3  4  6  3  4  6\n",
              "1199  3  3  3  3  3  3\n",
              "\n",
              "[1200 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "We4QqweCcxeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}