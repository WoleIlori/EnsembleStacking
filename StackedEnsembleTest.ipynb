{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackedEnsembleTest",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "qje27QyUvmEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot\n",
        "from random import randint\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from scipy.spatial import distance\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import ensemble\n",
        "from sklearn import linear_model\n",
        "from sklearn import neighbors\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OuElUqJaLZHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ff8c3c0b-e17f-4064-be8b-31e81cf5b83a"
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "omU9AKq8OwID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/My Drive/Dataset/fashion-mnist_train.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/Dataset/fashion-mnist_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b65AT9E3Uyvf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_classifier(classifier_type, tree_min_samples_split = 20):\n",
        "\n",
        "    if classifier_type == \"svm\":\n",
        "        c = svm.SVC(probability=True)\n",
        "\n",
        "    elif classifier_type == \"logreg\":\n",
        "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "\n",
        "    elif classifier_type == \"knn\":\n",
        "        c = neighbors.KNeighborsClassifier()\n",
        "\n",
        "    elif classifier_type == \"tree\":\n",
        "        c = tree.DecisionTreeClassifier(min_samples_split = tree_min_samples_split)\n",
        "\n",
        "    elif classifier_type == \"randomforest\":\n",
        "        c = ensemble.RandomForestClassifier()\n",
        "        \n",
        "    else:\n",
        "        c = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "    \n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4YXXAFycOw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create a sample of train_data for fast training\n",
        "data_sampling_rate = 0.01\n",
        "samp_data = train_data.sample(frac=data_sampling_rate)\n",
        "target = \"label\"\n",
        "X = [i for i in samp_data.columns if i not in target]\n",
        "X = samp_data[X]\n",
        "y = samp_data[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5LV1GgZ6oEN",
        "colab_type": "code",
        "outputId": "2a817f40-f715-4d8f-a9c4-59a1fd5d9515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "il2N4v5EcUFT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a new classifier which is based on the sckit-learn BaseEstimator and ClassifierMixin classes\n",
        "class StackedEnsembleClassifier(BaseEstimator, ClassifierMixin):\n",
        "    \n",
        "    \"\"\"An ensemble classifier that uses heterogeneous models at the base layer and a aggregatnio model at the aggregation layer. A k-fold cross validation is used to gnerate training data for the stack layer model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    base_estimators: list \n",
        "        A list of the classifiers in the ase layer of the ensemble. Supported types are\n",
        "        - \"svm\" Support Vector Machine implemented by sklearn.svm.SVC\n",
        "        - \"logreg\" Logistic Regression implemented by sklearn.linear_models.LogisticRegression\n",
        "        - \"knn\" k Nearest Neighbour implemented by sklearn.neighbors.KNeighborsClassifier\n",
        "        - \"tree\" Decision Tree implemented by sklearn.tree.DecisionTreeClassifier\n",
        "        - \"randomforest\" RandomForest implemented by sklearn.tree.RandomForestClassifier    \n",
        "    classifier_duplicates: int, optional (default = 1)\n",
        "        How many instances of each classifier type listed in base_estimators is included in the ensemble\n",
        "    stack_layer_classifier: string, optional (default = \"logreg')\n",
        "        The classifier type used at the stack layer. The same classifier types as are supported at the base layer are supported        \n",
        "    training_folds: int, optional (default = 4)\n",
        "        How many folds will be used to generate the training set for the stacked layer\n",
        "        \n",
        "    Attributes\n",
        "    ----------\n",
        "    classes_ : array of shape = [n_classes] \n",
        "        The classes labels (single output problem).\n",
        "\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    The default values for most base learners are used.\n",
        "\n",
        "    See also\n",
        "    --------\n",
        "    \n",
        "    ----------\n",
        "    .. [1]  van der Laan, M., Polley, E. & Hubbard, A. (2007). \n",
        "            Super Learner. Statistical Applications in Genetics \n",
        "            and Molecular Biology, 6(1) \n",
        "            doi:10.2202/1544-6115.1309\n",
        "    Examples\n",
        "    --------\n",
        "    >>> from sklearn.datasets import load_iris\n",
        "    >>> from sklearn.model_selection import cross_val_score\n",
        "    >>> clf = StackedEnsembleClassifier()\n",
        "    >>> iris = load_iris()\n",
        "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
        "\n",
        "    \"\"\"\n",
        "    # Constructor for the classifier object\n",
        "    def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
        "        \"\"\"Setup a SuperLearner classifier .\n",
        "        Parameters\n",
        "        ----------\n",
        "        base_estimator_types: The types of classifiers to include at the base layer\n",
        "        base_estimator_duplicates: The number of duplicates of each type of classiifer to include\n",
        "        stack_layer_classifier_type: The type of classifier to include at the stack layer \n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Nothing\n",
        "        \"\"\"     \n",
        "\n",
        "        # Initialise class variabels\n",
        "        self.base_estimator_types = base_estimator_types\n",
        "        self.base_estimator_type_list = list()\n",
        "        self.base_estimator_duplicates = base_estimator_duplicates\n",
        "        self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "\n",
        "    # The fit function to train a classifier\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Build a SuperLearner classifier from the training set (X, y).\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape = [n_samples, n_features]\n",
        "            The training input samples. \n",
        "        y : array-like, shape = [n_samples] \n",
        "            The target values (class labels) as integers or strings.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"    \n",
        "        \n",
        "        # Check that X and y have correct shape\n",
        "        X, y = check_X_y(X, y)\n",
        "        # Store the classes seen during fit\n",
        "        self.classes_ = unique_labels(y)\n",
        "        \n",
        "        ########################\n",
        "        # LEVEL 0\n",
        "        ########################\n",
        "        \n",
        "        # Set up the base classifeirs in the ensemble\n",
        "        self.classifiers_ = list()\n",
        "        \n",
        "        for i in range(0, self.base_estimator_duplicates):\n",
        "            for t in self.base_estimator_types:\n",
        "\n",
        "                self.base_estimator_type_list.append(t)      \n",
        "                c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "                self.classifiers_.append(c)\n",
        "        \n",
        "        # Store the number of classifers in the ensemble\n",
        "        self.n_estimators_ = len(self.classifiers_)\n",
        "\n",
        "        # Use all training data to train base classifiers\n",
        "        X_train = X\n",
        "        y_train = y\n",
        "        \n",
        "        # Set up empty arrays to hold stack layer training data\n",
        "        self.X_stack_train = None #(dtype = float)\n",
        "        self.y_stack_train = y_train\n",
        "          \n",
        "        # Train each base calssifier and generate the stack layer training dataset\n",
        "        for classifier in self.classifiers_:\n",
        "\n",
        "            # Extract a bootstrap sample\n",
        "            X_train_samp, y_train_samp = resample(X_train, y_train, replace=True)    \n",
        "            \n",
        "            # Train a base classifier\n",
        "            classifier.fit(X_train_samp, y_train_samp)\n",
        "            \n",
        "            # Make predictions for all instances in the training set\n",
        "            y_pred = classifier.predict_proba(X_train)\n",
        "\n",
        "            # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
        "            try:\n",
        "                self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
        "            except ValueError:\n",
        "                self.X_stack_train = y_pred\n",
        "      \n",
        "        ########################\n",
        "        # LEVEL 1\n",
        "        ########################\n",
        "        \n",
        "        # Create the stack layer classifier\n",
        "        self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "        # Train the stack layer using the newly created dataset\n",
        "        self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "            \n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict class labels of the input samples X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "        Returns\n",
        "        -------\n",
        "        p : array of shape = [n_samples, ].\n",
        "            The predicted class labels of the input samples. \n",
        "        \"\"\"\n",
        "        \n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "        # Check that the input features match the type and shape of the training features\n",
        "        X = check_array(X)\n",
        "   \n",
        "        X_stack_queries = None\n",
        "              \n",
        "        # Make a prediction with each base classifier and assemble the stack layer query\n",
        "        for classifier in self.classifiers_:\n",
        "            \n",
        "            y_pred = classifier.predict_proba(X)\n",
        "            \n",
        "            try:\n",
        "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "            except ValueError:\n",
        "                X_stack_queries = y_pred\n",
        "        \n",
        "        # Return the prediction made by the stack layer classifier\n",
        "        return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "    \n",
        "    # The predict function to make a set of predictions for a set of query instances\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"Predict class probabilities of the input samples X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "        Returns\n",
        "        -------\n",
        "        p : array of shape = [n_samples, n_labels].\n",
        "            The predicted class label probabilities of the input samples. \n",
        "        \"\"\"\n",
        "        # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "        check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "        # Check that the input features match the type and shape of the training features\n",
        "        X = check_array(X)\n",
        "        \n",
        "        X_stack_queries = None\n",
        "        \n",
        "        # Make a prediction with each base classifier\n",
        "        for classifier in self.classifiers_:\n",
        "            \n",
        "            y_pred = classifier.predict_proba(X)\n",
        "                \n",
        "            try:\n",
        "                X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "            except ValueError:\n",
        "                X_stack_queries = y_pred\n",
        "\n",
        "        # Return the prediction made by the stack layer classifier        \n",
        "        return self.stack_layer_classifier_.predict_proba(X_stack_queries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q2xcfenisLII",
        "colab_type": "code",
        "outputId": "1378eddd-4c46-4036-807e-642ade0ed4f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "cell_type": "code",
      "source": [
        "clf_standard = StackedEnsembleClassifier()\n",
        "clf_standard.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedEnsembleClassifier(base_estimator_duplicates=8,\n",
              "             base_estimator_types=['svm', 'logreg', 'tree'],\n",
              "             stack_layer_classifier_type='logreg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "NEf24Z066spb",
        "colab_type": "code",
        "outputId": "30b2570a-88f1-4905-9762-8e580cec5655",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf_standard.X_stack_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "VC7SSxIfVAGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class StackedEnsembleHoldOut(BaseEstimator, ClassifierMixin):\n",
        "  # Constructor for the classifier object\n",
        "  def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
        "    # Initialise class variabels\n",
        "    self.base_estimator_types = base_estimator_types\n",
        "    self.base_estimator_type_list = list()\n",
        "    self.base_estimator_duplicates = base_estimator_duplicates\n",
        "    self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "\n",
        "  # The fit function to train a classifier\n",
        "  def fit(self, X, y):\n",
        "    # Check that X and y have correct shape\n",
        "    X, y = check_X_y(X, y)\n",
        "        \n",
        "    # Store the classes seen during fit\n",
        "    self.classes_ = unique_labels(y)\n",
        "        \n",
        "    # Set up the base classifeirs in the ensemble\n",
        "    self.classifiers_ = list()\n",
        "    \n",
        "    for i in range(0, self.base_estimator_duplicates):\n",
        "      \n",
        "      for t in self.base_estimator_types:\n",
        "        \n",
        "        self.base_estimator_type_list.append(t)      \n",
        "        c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "        self.classifiers_.append(c)\n",
        "        \n",
        "    # Store the number of classifers in the ensemble\n",
        "    self.n_estimators_ = len(self.classifiers_)\n",
        "        \n",
        "    # Set up empty arrays to hold stack layer training data\n",
        "    self.X_stack_train = None #(dtype = float)\n",
        "    self.y_stack_train = None\n",
        "  \n",
        "    #create a hold out set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\\\n",
        "                                                              train_size = 0.8)\n",
        "    \n",
        "    self.X_train = X_train\n",
        "    # Append the true value of hold out set to y_stack_train\n",
        "    try:\n",
        "      self.y_stack_train = np.c_[self.y_stack_train, y_test]\n",
        "    except ValueError:\n",
        "      self.y_stack_train = y_test #* might need to change\n",
        "    \n",
        "    for classifier in self.classifiers_:\n",
        "      # Train a base classifier\n",
        "      classifier.fit(X_train, y_train)\n",
        "      \n",
        "      # Make predictions for all instances in the hold out set\n",
        "      y_pred = classifier.predict_proba(X_test)\n",
        "\n",
        "      # Append the predictions ot the stack layer traing set (a bit of hacking here!)\n",
        "      try:\n",
        "        self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
        "      except ValueError:\n",
        "        self.X_stack_train = y_pred #* might need to change\n",
        "    \n",
        "    # Create the stack layer classifier\n",
        "    self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "    # Train the stack layer using the newly created dataset\n",
        "    self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "                \n",
        "    return self\n",
        "    \n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict(self, X):\n",
        "    \"\"\"Predict class labels of the input samples X.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like matrix of shape = [n_samples, n_features]\n",
        "    \n",
        "    The input samples. \n",
        "    Returns\n",
        "    -------\n",
        "    p : array of shape = [n_samples, ].\n",
        "            The predicted class labels of the input samples. \n",
        "        \"\"\"\n",
        "        \n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "   \n",
        "    X_stack_queries = None\n",
        "              \n",
        "    # Make a prediction with each base classifier and assemble the stack layer query\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      \n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "        \n",
        "    # Return the prediction made by the stack layer classifier\n",
        "    return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "      \n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict_proba(self, X):\n",
        "    \"\"\"Predict class probabilities of the input samples X.\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array-like matrix of shape = [n_samples, n_features]\n",
        "            The input samples. \n",
        "    Returns\n",
        "    -------\n",
        "    p : array of shape = [n_samples, n_labels].\n",
        "         The predicted class label probabilities of the input samples. \n",
        "        \"\"\"\n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "        \n",
        "    X_stack_queries = None\n",
        "        \n",
        "    # Make a prediction with each base classifier\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      \n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "\n",
        "    # Return the prediction made by the stack layer classifier        \n",
        "    return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LlRQKwRw28Ur",
        "colab_type": "code",
        "outputId": "772f2c60-e89a-4b45-852b-e1a9a6ad319b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "clf_holdout = StackedEnsembleHoldOut()\n",
        "clf_holdout.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedEnsembleHoldOut(base_estimator_duplicates=8,\n",
              "            base_estimator_types=['svm', 'logreg', 'tree'],\n",
              "            stack_layer_classifier_type='logreg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "ETHBhvMhtOWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class StackedEnsembleKFold(BaseEstimator, ClassifierMixin):\n",
        "  #fields\n",
        "  \n",
        "  # Constructor for the classifier object\n",
        "  def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
        "    # Initialise class variabels\n",
        "    self.base_estimator_types = base_estimator_types\n",
        "    self.base_estimator_type_list = list()\n",
        "    self.base_estimator_duplicates = base_estimator_duplicates\n",
        "    self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "    \n",
        "  # The fit function to train a classifier\n",
        "  def fit(self, X, y):\n",
        "    # Check that X and y have correct shape\n",
        "    X, y = check_X_y(X, y)\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    # Store the classes seen during fit\n",
        "    self.classes_ = unique_labels(y)\n",
        "        \n",
        "    # Set up the base classifeirs in the ensemble\n",
        "    self.classifiers_ = list()\n",
        "    \n",
        "    for i in range(0, self.base_estimator_duplicates):\n",
        "      for t in self.base_estimator_types:\n",
        "        self.base_estimator_type_list.append(t)      \n",
        "        c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "        self.classifiers_.append(c)\n",
        "        \n",
        "    # Store the number of classifers in the ensemble\n",
        "    self.n_estimators_ = len(self.classifiers_)\n",
        "        \n",
        "    # Set up empty arrays to hold stack layer training data\n",
        "    self.X_stack_train = None #(dtype = float)\n",
        "    self.y_stack_train = None\n",
        "    \n",
        "        \n",
        "    # Train each base classifier and generate the stack layer training dataset\n",
        "    kf = KFold(n_splits=3)\n",
        "        \n",
        "    for train_index, test_index in kf.split(X):\n",
        "      X_train, X_test = X[train_index], X[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "      X_fold =None\n",
        "\n",
        "      # Append the true value for X_test in i fold to y_stack_train (a bit of hacking here!)\n",
        "      try:\n",
        "        self.y_stack_train = np.concatenate((self.y_stack_train, y_test), axis=0)\n",
        "      except ValueError:\n",
        "        self.y_stack_train = y_test\n",
        "             \n",
        "      for classifier in self.classifiers_:\n",
        "        \n",
        "        # Train a base classifier\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions for all instances in the training set\n",
        "        y_pred = classifier.predict_proba(X_test)\n",
        "        \n",
        "        try:\n",
        "          X_fold= np.c_[X_fold, y_pred]\n",
        "        except ValueError:\n",
        "          X_fold = y_pred\n",
        "      \n",
        "      try:\n",
        "          self.X_stack_train = np.concatenate((self.X_stack_train, X_fold), axis=0)\n",
        "      except ValueError:\n",
        "          self.X_stack_train = X_fold\n",
        "      \n",
        "      \n",
        "    \n",
        "    # Create the stack layer classifier\n",
        "    self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "    # Train the stack layer using the newly created dataset\n",
        "    self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "        \n",
        "    return self\n",
        "\n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict(self, X):\n",
        "    \n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "   \n",
        "    X_stack_queries = None\n",
        "              \n",
        "    # Make a prediction with each base classifier and assemble the stack layer query\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "      \n",
        "    # Return the prediction made by the stack layer classifier\n",
        "    return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "      \n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict_proba(self, X):\n",
        "    \n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "        \n",
        "    X_stack_queries = None\n",
        "        \n",
        "    # Make a prediction with each base classifier\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "\n",
        "    # Return the prediction made by the stack layer classifier        \n",
        "    return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G6bgLvzNtsSb",
        "colab_type": "code",
        "outputId": "282bcad9-30c0-4c42-906e-ae32cb907e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "cell_type": "code",
      "source": [
        "clf_kfold = StackedEnsembleKFold()\n",
        "clf_kfold.fit(X, y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedEnsembleKFold(base_estimator_duplicates=8,\n",
              "           base_estimator_types=['svm', 'logreg', 'tree'],\n",
              "           stack_layer_classifier_type='logreg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "oHdxacxS0aM4",
        "colab_type": "code",
        "outputId": "01071d5e-9395-4645-c45e-f2bb6127243b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "clf_kfold.X_stack_train"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 240)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "GNhOebsHt3_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class StackedEnsembleOnevsOne(BaseEstimator, ClassifierMixin):\n",
        "  \n",
        "  # Constructor for the classifier object\n",
        "  def __init__(self, base_estimator_types = [\"svm\", \"logreg\", \"tree\"], base_estimator_duplicates = 8, stack_layer_classifier_type = \"logreg\"):\n",
        "    \n",
        "    # Initialise class variabels\n",
        "    self.base_estimator_types = base_estimator_types\n",
        "    self.base_estimator_type_list = list()\n",
        "    self.base_estimator_duplicates = base_estimator_duplicates\n",
        "    self.stack_layer_classifier_type = stack_layer_classifier_type\n",
        "\n",
        "  # The fit function to train a classifier\n",
        "  def fit(self, X, y):\n",
        "    # Check that X and y have correct shape\n",
        "    X, y = check_X_y(X, y)\n",
        "\n",
        "    # Store the classes seen during fit\n",
        "    self.classes_ = unique_labels(y)\n",
        "\n",
        "    #store the number of unique class\n",
        "    num_class = len(self.classes_)\n",
        "\n",
        "    # Set up the base classifeirs in the ensemble\n",
        "    self.classifiers_ = list()\n",
        "    \n",
        "    #calculate the number of models needed using the formula: n!/k!(n-k)!\n",
        "    n_models = math.factorial(num_class) / (math.factorial(2) * math.factorial((num_class - 2)))\n",
        "    \n",
        "    duplicates = int(n_models / len(self.base_estimator_types))\n",
        "    for i in range(0,duplicates):\n",
        "      for t in self.base_estimator_types:\n",
        "          self.base_estimator_type_list.append(t)      \n",
        "          c = create_classifier(t, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "          self.classifiers_.append(c)\n",
        "    \n",
        "    # Store the number of classifers in the ensemble\n",
        "    self.n_estimators_ = len(self.classifiers_)\n",
        "\n",
        "    # Set up empty arrays to hold stack layer training data\n",
        "    self.X_stack_train = None #(dtype = float)\n",
        "    self.y_stack_train = None\n",
        "\n",
        "    #create a hold out set\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,\\\n",
        "                                                                train_size = 0.8)\n",
        "\n",
        "    # Append the truth value to the stack layer training set (a bit of hacking here!)\n",
        "    try: \n",
        "      self.y_stack_train = np.c_[self.y_stack_train, y]\n",
        "    except ValueError:\n",
        "      self.y_stack_train = y\n",
        "\n",
        "    #append y_train column to X_train\n",
        "    X_train = np.c_[X_train, y_train]\n",
        "\n",
        "    X_train = pd.DataFrame(X_train)\n",
        "\n",
        "    #get the index for the target column\n",
        "    target = len(X_train.columns) - 1\n",
        "\n",
        "    n=0\n",
        "    for i in range(num_class):\n",
        "      #check if num of models created is equal to the size needed\n",
        "      if n < n_models:\n",
        "        \n",
        "        for j in range(i+1, num_class):\n",
        "          \n",
        "          #get the instances that contain i class\n",
        "          i_instances = X_train[X_train[target] == self.classes_[i]]\n",
        "\n",
        "          #get the instances that contain j class\n",
        "          j_instances = X_train[X_train[target] == self.classes_[j]]\n",
        "\n",
        "          #add both i and j instances\n",
        "          combine= pd.concat([i_instances,j_instances])\n",
        "          X_train_model = combine[combine.columns.difference([target])]\n",
        "          y_train_model = combine[target]\n",
        "\n",
        "          #create a model for X_train_model and y_train_model\n",
        "          classifier = self.classifiers_[n]\n",
        "\n",
        "          n += 1\n",
        "          \n",
        "          #Train a base classifier\n",
        "          classifier.fit(np.array(X_train_model), np.array(y_train_model))\n",
        "\n",
        "          #Get the output for the model\n",
        "          y_pred = classifier.predict_proba(X)\n",
        "\n",
        "          # Append the predictions to the stack layer training set (a bit of hacking here!)\n",
        "          try:\n",
        "            self.X_stack_train = np.c_[self.X_stack_train, y_pred]\n",
        "          except ValueError:\n",
        "            self.X_stack_train = y_pred\n",
        "\n",
        "    # Create the stack layer classifier\n",
        "    self.stack_layer_classifier_ = create_classifier(self.stack_layer_classifier_type, tree_min_samples_split=math.ceil(len(X)*0.05))\n",
        "\n",
        "    # Train the stack layer using the newly created dataset\n",
        "    self.stack_layer_classifier_.fit(self.X_stack_train, self.y_stack_train)\n",
        "   \n",
        "    return self\n",
        "\n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict(self, X):\n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "\n",
        "    X_stack_queries = None\n",
        "\n",
        "    # Make a prediction with each base classifier and assemble the stack layer query\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "\n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "\n",
        "    # Return the prediction made by the stack layer classifier\n",
        "    return self.stack_layer_classifier_.predict(X_stack_queries)\n",
        "\n",
        "  # The predict function to make a set of predictions for a set of query instances\n",
        "  def predict_proba(self, X):\n",
        "    # Check is fit had been called by confirming that the teamplates_ dictiponary has been set up\n",
        "    check_is_fitted(self, ['stack_layer_classifier_'])\n",
        "\n",
        "    # Check that the input features match the type and shape of the training features\n",
        "    X = check_array(X)\n",
        "\n",
        "    X_stack_queries = None\n",
        "\n",
        "    # Make a prediction with each base classifier\n",
        "    for classifier in self.classifiers_:\n",
        "      y_pred = classifier.predict_proba(X)\n",
        "      try:\n",
        "        X_stack_queries = np.c_[X_stack_queries, y_pred]\n",
        "      except ValueError:\n",
        "        X_stack_queries = y_pred\n",
        "\n",
        "    # Return the prediction made by the stack layer classifier        \n",
        "    return self.stack_layer_classifier_.predict_proba(X_stack_queries)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLIFBGVKuCcG",
        "colab_type": "code",
        "outputId": "1a9642b7-a53d-436f-e7ee-adb255603550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "cell_type": "code",
      "source": [
        "clf_1v1 = StackedEnsembleOnevsOne()\n",
        "clf_1v1.fit(X, y)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StackedEnsembleOnevsOne(base_estimator_duplicates=8,\n",
              "            base_estimator_types=['svm', 'logreg', 'tree'],\n",
              "            stack_layer_classifier_type='logreg')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "TEJ09Mu9oIWg",
        "colab_type": "code",
        "outputId": "d4d8a195-5b53-4822-c764-6d71f85087a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "sE9tdB0tS_G1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evalulation Framework\n",
        "This will be used to evaluate the performance of the first 3 stacking approaches:\n",
        "StackedEnsembleClassifier, StackedEnsembleHoldOut and StackedEnsemble KFold"
      ]
    },
    {
      "metadata": {
        "id": "o2YcjHlF176z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create a sample of train_data for fast training\n",
        "data_sampling_rate = 0.1\n",
        "samp_data = test_data.sample(frac=data_sampling_rate)\n",
        "target = \"label\"\n",
        "X_test = [i for i in samp_data.columns if i not in target]\n",
        "X_test = samp_data[X_test]\n",
        "y_test = samp_data[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WJXHzhzTS81z",
        "colab_type": "code",
        "outputId": "862a6b02-4451-4842-d9a2-d4a8e996003b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#1.confusion Matrix\n",
        "standard_y_pred=clf_standard.predict(X_test)\n",
        "clf_standard_acc = metrics.accuracy_score(y_test, standard_y_pred)\n",
        "print(\"StackedEnsembleClassifier Accuracy: \" + str(clf_standard_acc))\n",
        "#.802 Answer for 1% training and 10 %test\n",
        "#print(metrics.classification_report(y_test, y_pred))\n",
        "#2.ROC\n",
        "#3.Cross Validation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "StackedEnsembleClassifier Accuracy: 0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bsr7WdKA5J5w",
        "colab_type": "code",
        "outputId": "3a31b256-6005-4dbb-b64c-55a45b929735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "holdout_y_pred=clf_holdout.predict(X_test)\n",
        "clf_holdout_acc = metrics.accuracy_score(y_test, holdout_y_pred)\n",
        "print(\"\\nStackedEnsembleHoldout Accuracy: \" + str(clf_holdout_acc))\n",
        "#.741 Answer for 1% training and 10 %test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "StackedEnsembleHoldout Accuracy: 0.741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2KxzXCgIGy-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "61a8b3f9-6e9c-4dfe-8c90-564ed14ec214"
      },
      "cell_type": "code",
      "source": [
        "kfold_y_pred = clf_kfold.predict(X_test)\n",
        "clf_kfold_acc = metrics.accuracy_score(y_test, kfold_y_pred)\n",
        "print(\"\\nStackedEnsembleKfold Accuracy: \" + str(clf_kfold_acc))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stacked EnsembleKfold Accuracy: 0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E0wZnf06HdKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9ed1a5e6-beeb-45f4-857a-36b010842ede"
      },
      "cell_type": "code",
      "source": [
        "v1_y_pred = clf_1v1.predict(X_test)\n",
        "clf_1v1_acc = metrics.accuracy_score(y_test, v1_y_pred)\n",
        "print(\"\\nStackedEnsemble1v1 Accuracy: \" + str(clf_1v1_acc))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "StackedEnsemble1v1 Accuracy: 0.717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jWW9isb6TKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the parameter grid to seaerch\n",
        "param_grid ={'criterion': ['gini', \"entropy\"], \\\n",
        "             'max_depth': list(range(3, 20, 3)), \\\n",
        "             'min_samples_split': [50] }\n",
        "\n",
        "# Perform the search\n",
        "my_tuned_tree = GridSearchCV(tree.DecisionTreeClassifier(), \\\n",
        "                                param_grid, cv=2, verbose = 0, \\\n",
        "                            return_train_score=True)\n",
        "my_tuned_tree.fit(X_train_plus_valid, y_train_plus_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcys_Qc1VB8R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up the parameter grid to seaerch\n",
        "param_grid =[{'base_estimator': 'tree.DecisionTreeClassifier()', \\\n",
        "              'base_estimator__criterion':['gini', 'entropy'],\\\n",
        "              'base_estimator__max_depth': list(range(3, 12, 3)),\\\n",
        "              'n_estimators': list(range(3, 9, 3))},\\\n",
        "             {'base_estimator': 'neighbor.KNeighborsClassifier()',\\\n",
        "              'base_estimator__n_neigbours': list(range(1, 10, 3)),\n",
        "              'base_estimator__metric': ['minkowski', 'euclidean']\n",
        "             }]\n",
        "\n",
        "# Perform the search\n",
        "my_tuned_model = GridSearchCV(ensemble.BaggingClassifier(), \\\n",
        "                                param_grid, cv=2, verbose = 0, \\\n",
        "                            return_train_score=True)\n",
        "\n",
        "#\n",
        "my_tuned_model.fit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2g5SMjNCfzub",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#OR\n",
        "estimators = []\n",
        "estimators.append(tree.DecisionTreeClassifier())\n",
        "estimators.append(neighbor.KNeighborsClassifier())\n",
        "\n",
        "estimator_grids = []\n",
        "tree_grid = {'base_estimator__criterion':['gini', 'entropy'],\\\n",
        "             'base_estimator__max_depth': list(range(3, 12, 3)),\\\n",
        "             'n_estimators': list(range(3, 9, 3))}\n",
        "\n",
        "knn_grid = {'base_estimator__n_neigbours': list(range(1, 10, 3)),\\\n",
        "            'base_estimator__metric': ['minkowski', 'euclidean'],\\\n",
        "            'n_estimators': list(range(3, 9, 3))}\n",
        "\n",
        "estimator_grids.append(tree_grid)\n",
        "estimator_grids.append(knn_grid)\n",
        "\n",
        "tuned_models = []\n",
        "for i in range(len(estimators)):\n",
        "  # Perform the search\n",
        "  tuned_models[i] = GridSearchCV(estimator = estimators[i], \\\n",
        "                                param_grid = estimator_grids[i], cv=2, verbose = 0, \\\n",
        "                                return_train_score=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V9x47IEBnagi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fit best descision tree model\n",
        "tuned_tree = tuned_models[0]\n",
        "tuned_tree.fit()\n",
        "\n",
        "#fit best knn model\n",
        "tuned_knn = tuned_models[1]\n",
        "tuned_knn.fit()\n",
        "\n",
        "#find the best classifier for bagging\n",
        "if tuned_tree.best_score > tuned_knn.best_score:\n",
        "  best_classifier = tuned_tree\n",
        "else:\n",
        "  best_classifier = tuned_knn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "We4QqweCcxeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}